{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMvRvQbJykxM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import timm\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VZshZ4nPywbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a91561-b677-4d75-d1e8-667968db4eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path=\"/content/drive/MyDrive/Research_project/TrashNeXt Dataset.zip\"\n",
        "extract_path = \"/content\"\n"
      ],
      "metadata": {
        "id": "XPs9cJQDyyNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Dataset extracted to:\", extract_path)\n",
        "!ls {extract_path}"
      ],
      "metadata": {
        "id": "DCe7LIlZy0WK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44027008-6d64-46ce-8357-08c516c4a21a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted to: /content\n",
            " drive\t __MACOSX   sample_data  'TrashNeXt Dataset'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "def is_corrupted_image(file_path):\n",
        "    \"\"\"Check if an image file is corrupted.\"\"\"\n",
        "    try:\n",
        "        with Image.open(file_path) as img:\n",
        "            img.verify()  # Verify integrity\n",
        "        return False\n",
        "    except (IOError, SyntaxError, Image.DecompressionBombError):\n",
        "        return True\n",
        "\n",
        "def remove_corrupted_images(dataset_path):\n",
        "    \"\"\"Scan and remove corrupted images + hidden macOS files.\"\"\"\n",
        "    corrupted_count = 0\n",
        "    total_images = 0\n",
        "\n",
        "    for root, _, files in os.walk(dataset_path):\n",
        "        for file in tqdm(files, desc=f\"Scanning {os.path.basename(root)}\"):\n",
        "\n",
        "            # Skip hidden files (.DS_Store, ._files)\n",
        "            if file.startswith(\".\"):\n",
        "                file_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    os.remove(file_path)\n",
        "                    corrupted_count += 1\n",
        "                    print(f\"Removed hidden file: {file_path}\")\n",
        "                except:\n",
        "                    pass\n",
        "                continue\n",
        "\n",
        "            # Check only image formats\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "                total_images += 1\n",
        "                file_path = os.path.join(root, file)\n",
        "                if is_corrupted_image(file_path):\n",
        "                    try:\n",
        "                        os.remove(file_path)\n",
        "                        corrupted_count += 1\n",
        "                        print(f\"Removed corrupted image: {file_path}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error removing {file_path}: {e}\")\n",
        "\n",
        "    print(\"\\n‚úÖ Scan completed!\")\n",
        "    print(f\"üì∑ Total images scanned: {total_images}\")\n",
        "    print(f\"üóëÔ∏è Corrupted/hidden files removed: {corrupted_count}\")\n",
        "\n",
        "# Run the cleaner\n",
        "dataset_path = '/content/dataset'  # Your dataset path\n",
        "remove_corrupted_images(dataset_path)\n"
      ],
      "metadata": {
        "id": "IBfhAkJAy3Bh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7de1994-f4e1-43e3-b46c-4f8144e5b989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Scanning dataset: 0it [00:00, ?it/s]\n",
            "Scanning Train: 0it [00:00, ?it/s]\n",
            "Scanning metal: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2065/2065 [00:00<00:00, 8162.13it/s]\n",
            "Scanning medical: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1565/1565 [00:00<00:00, 9539.55it/s]\n",
            "Scanning foam_rubber: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2289/2289 [00:00<00:00, 10587.54it/s]\n",
            "Scanning cardboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1886/1886 [00:00<00:00, 10864.73it/s]\n",
            "Scanning e-waste: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2404/2404 [00:00<00:00, 8752.26it/s]\n",
            "Scanning glass: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2009/2009 [00:00<00:00, 8929.06it/s]\n",
            "Scanning organic: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2391/2391 [00:00<00:00, 15908.91it/s]\n",
            "Scanning paper: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2155/2155 [00:00<00:00, 10898.36it/s]\n",
            "Scanning plastic: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2135/2135 [00:00<00:00, 7483.87it/s]\n",
            "Scanning Test: 0it [00:00, ?it/s]\n",
            "Scanning metal: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 258/258 [00:00<00:00, 7616.94it/s]\n",
            "Scanning medical: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 196/196 [00:00<00:00, 7840.64it/s]\n",
            "Scanning foam_rubber: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 287/287 [00:00<00:00, 8987.82it/s]\n",
            "Scanning cardboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 235/235 [00:00<00:00, 11272.56it/s]\n",
            "Scanning e-waste: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 301/301 [00:00<00:00, 7487.21it/s]\n",
            "Scanning glass: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 252/252 [00:00<00:00, 10722.66it/s]\n",
            "Scanning organic: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 299/299 [00:00<00:00, 16069.51it/s]\n",
            "Scanning paper: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 270/270 [00:00<00:00, 8703.55it/s]\n",
            "Scanning plastic: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 267/267 [00:00<00:00, 8238.95it/s]\n",
            "Scanning Valid: 0it [00:00, ?it/s]\n",
            "Scanning metal: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 258/258 [00:00<00:00, 9152.99it/s]\n",
            "Scanning medical: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 196/196 [00:00<00:00, 7021.49it/s]\n",
            "Scanning foam_rubber: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 287/287 [00:00<00:00, 8158.91it/s]\n",
            "Scanning cardboard: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 236/236 [00:00<00:00, 8964.22it/s]\n",
            "Scanning e-waste: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 301/301 [00:00<00:00, 7277.33it/s]\n",
            "Scanning glass: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 251/251 [00:00<00:00, 7855.21it/s]\n",
            "Scanning organic: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 299/299 [00:00<00:00, 12545.74it/s]\n",
            "Scanning paper: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 269/269 [00:00<00:00, 10130.26it/s]\n",
            "Scanning plastic: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 267/267 [00:00<00:00, 7011.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Scan completed!\n",
            "üì∑ Total images scanned: 23625\n",
            "üóëÔ∏è Corrupted/hidden files removed: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def remove_truncated_images(dataset_path):\n",
        "    removed_count = 0  # Counter for removed images\n",
        "\n",
        "    for root, _, files in os.walk(dataset_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                img_path = os.path.join(root, file)\n",
        "                try:\n",
        "                    img = Image.open(img_path)\n",
        "                    img.verify()  # Verify if the image is not corrupted\n",
        "                    img.close()   # Close the image to avoid resource leaks\n",
        "                except Exception as e:\n",
        "                    print(f\"Removing corrupted/truncated: {img_path}\")\n",
        "                    os.remove(img_path)\n",
        "                    removed_count += 1\n",
        "\n",
        "    print(f\"\\nTotal corrupted/truncated images removed: {removed_count}\")\n",
        "\n",
        "# Example usage\n",
        "dataset_path = \"/content/dataset\"\n",
        "remove_truncated_images(dataset_path)"
      ],
      "metadata": {
        "id": "pqevg6YPy6Mq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47f0983c-3567-4fa4-a1aa-80953df2d2e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total corrupted/truncated images removed: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "metadata": {
        "id": "IkKN5vo5E4Dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVQAa-LxFQvh",
        "outputId": "54553ca1-e66d-40b9-aa82-e0e6cc918053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# üîπ Paths\n",
        "train_dir = \"/content/dataset/Train\"\n",
        "valid_dir = \"/content/dataset/Valid\"\n",
        "test_dir  = \"/content/dataset/Test\"\n",
        "\n",
        "# üîπ Transforms (CoAtNet standard: 224x224)\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "valid_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "# üîπ Datasets & Loaders\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
        "valid_dataset = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n",
        "test_dataset  = datasets.ImageFolder(test_dir,  transform=valid_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False)\n",
        "\n",
        "# Print class names\n",
        "print(f\"Classes: {train_dataset.classes}\")\n",
        "print(f\"Number of classes: {len(train_dataset.classes)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adhHHwb6FVfa",
        "outputId": "f5b68fdf-fc9e-4908-a343-39fbafd430ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['cardboard', 'e-waste', 'foam_rubber', 'glass', 'medical', 'metal', 'organic', 'paper', 'plastic']\n",
            "Number of classes: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_classes = len(train_dataset.classes)\n",
        "model = timm.create_model(\"coatnet_0_rw_224\", pretrained=True, num_classes=num_classes)\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "InOqWK6yFeNw",
        "outputId": "851acb72-3927-47bb-bc81-b58a00b13070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MaxxVit(\n",
              "  (stem): Stem(\n",
              "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (norm1): BatchNormAct2d(\n",
              "      32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  )\n",
              "  (stages): Sequential(\n",
              "    (0): MaxxVitStage(\n",
              "      (blocks): Sequential(\n",
              "        (0): MbConvBlock(\n",
              "          (shortcut): Downsample2d(\n",
              "            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "            (expand): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          )\n",
              "          (pre_norm): BatchNormAct2d(\n",
              "            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (down): Downsample2d(\n",
              "            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "            (expand): Identity()\n",
              "          )\n",
              "          (conv1_1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm1): BatchNormAct2d(\n",
              "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2_kxk): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
              "          (se_early): SEModule(\n",
              "            (fc1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (bn): Identity()\n",
              "            (act): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (norm2): BatchNormAct2d(\n",
              "            256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv3_1x1): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): MbConvBlock(\n",
              "          (shortcut): Identity()\n",
              "          (pre_norm): BatchNormAct2d(\n",
              "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (down): Identity()\n",
              "          (conv1_1x1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm1): BatchNormAct2d(\n",
              "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2_kxk): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (se_early): SEModule(\n",
              "            (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (bn): Identity()\n",
              "            (act): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (norm2): BatchNormAct2d(\n",
              "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv3_1x1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): MaxxVitStage(\n",
              "      (blocks): Sequential(\n",
              "        (0): MbConvBlock(\n",
              "          (shortcut): Downsample2d(\n",
              "            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "            (expand): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          )\n",
              "          (pre_norm): BatchNormAct2d(\n",
              "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (down): Downsample2d(\n",
              "            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "            (expand): Identity()\n",
              "          )\n",
              "          (conv1_1x1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm1): BatchNormAct2d(\n",
              "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2_kxk): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (se_early): SEModule(\n",
              "            (fc1): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (bn): Identity()\n",
              "            (act): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (norm2): BatchNormAct2d(\n",
              "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv3_1x1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): MbConvBlock(\n",
              "          (shortcut): Identity()\n",
              "          (pre_norm): BatchNormAct2d(\n",
              "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (down): Identity()\n",
              "          (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm1): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "          (se_early): SEModule(\n",
              "            (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (bn): Identity()\n",
              "            (act): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (norm2): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): MbConvBlock(\n",
              "          (shortcut): Identity()\n",
              "          (pre_norm): BatchNormAct2d(\n",
              "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (down): Identity()\n",
              "          (conv1_1x1): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (norm1): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv2_kxk): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "          (se_early): SEModule(\n",
              "            (fc1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (bn): Identity()\n",
              "            (act): ReLU(inplace=True)\n",
              "            (fc2): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (norm2): BatchNormAct2d(\n",
              "            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv3_1x1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): MaxxVitStage(\n",
              "      (blocks): Sequential(\n",
              "        (0): TransformerBlock2d(\n",
              "          (shortcut): Downsample2d(\n",
              "            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "            (expand): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          )\n",
              "          (norm1): Sequential(\n",
              "            (norm): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
              "            (down): Downsample2d(\n",
              "              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "              (expand): Identity()\n",
              "            )\n",
              "          )\n",
              "          (attn): Attention2d(\n",
              "            (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (rel_pos): RelPosBias()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): ConvMlp(\n",
              "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (norm): Identity()\n",
              "            (act): GELU()\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (1): TransformerBlock2d(\n",
              "          (shortcut): Identity()\n",
              "          (norm1): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention2d(\n",
              "            (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (rel_pos): RelPosBias()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): ConvMlp(\n",
              "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (norm): Identity()\n",
              "            (act): GELU()\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (2): TransformerBlock2d(\n",
              "          (shortcut): Identity()\n",
              "          (norm1): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention2d(\n",
              "            (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (rel_pos): RelPosBias()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): ConvMlp(\n",
              "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (norm): Identity()\n",
              "            (act): GELU()\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (3): TransformerBlock2d(\n",
              "          (shortcut): Identity()\n",
              "          (norm1): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention2d(\n",
              "            (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (rel_pos): RelPosBias()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): ConvMlp(\n",
              "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (norm): Identity()\n",
              "            (act): GELU()\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (4): TransformerBlock2d(\n",
              "          (shortcut): Identity()\n",
              "          (norm1): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention2d(\n",
              "            (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (rel_pos): RelPosBias()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): ConvMlp(\n",
              "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (norm): Identity()\n",
              "            (act): GELU()\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (5): TransformerBlock2d(\n",
              "          (shortcut): Identity()\n",
              "          (norm1): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention2d(\n",
              "            (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (rel_pos): RelPosBias()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): ConvMlp(\n",
              "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (norm): Identity()\n",
              "            (act): GELU()\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (6): TransformerBlock2d(\n",
              "          (shortcut): Identity()\n",
              "          (norm1): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention2d(\n",
              "            (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (rel_pos): RelPosBias()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): ConvMlp(\n",
              "            (fc1): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (norm): Identity()\n",
              "            (act): GELU()\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): MaxxVitStage(\n",
              "      (blocks): Sequential(\n",
              "        (0): TransformerBlock2d(\n",
              "          (shortcut): Downsample2d(\n",
              "            (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "            (expand): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          )\n",
              "          (norm1): Sequential(\n",
              "            (norm): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
              "            (down): Downsample2d(\n",
              "              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "              (expand): Identity()\n",
              "            )\n",
              "          )\n",
              "          (attn): Attention2d(\n",
              "            (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (rel_pos): RelPosBias()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): ConvMlp(\n",
              "            (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (norm): Identity()\n",
              "            (act): GELU()\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "        (1): TransformerBlock2d(\n",
              "          (shortcut): Identity()\n",
              "          (norm1): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (attn): Attention2d(\n",
              "            (qkv): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (rel_pos): RelPosBias()\n",
              "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "            (proj): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (ls1): Identity()\n",
              "          (drop_path1): Identity()\n",
              "          (norm2): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
              "          (mlp): ConvMlp(\n",
              "            (fc1): Conv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (norm): Identity()\n",
              "            (act): GELU()\n",
              "            (drop): Dropout(p=0.0, inplace=False)\n",
              "            (fc2): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (ls2): Identity()\n",
              "          (drop_path2): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
              "  (head): ClassifierHead(\n",
              "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "    (drop): Dropout(p=0.0, inplace=False)\n",
              "    (fc): Linear(in_features=768, out_features=9, bias=True)\n",
              "    (flatten): Identity()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ Loss & Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-4)"
      ],
      "metadata": {
        "id": "zzj1w1psGPsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîπ Training Loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1} - Training\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # üîπ Track loss & accuracy\n",
        "        running_loss += loss.item()\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = 100. * correct / total\n",
        "\n",
        "    # üîπ Validation\n",
        "    model.eval()\n",
        "    val_correct, val_total = 0, 0\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in valid_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, preds = outputs.max(1)\n",
        "            val_correct += preds.eq(labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    val_acc = 100. * val_correct / val_total\n",
        "    print(f\"\\nEpoch [{epoch+1}/{epochs}] \"\n",
        "          f\"Train Loss: {running_loss/len(train_loader):.4f} | \"\n",
        "          f\"Train Acc: {train_acc:.2f}% | \"\n",
        "          f\"Valid Loss: {val_loss/len(valid_loader):.4f} | \"\n",
        "          f\"Valid Acc: {val_acc:.2f}%\")\n"
      ],
      "metadata": {
        "id": "fzhwWgNBzvI9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c431a9cd-9632-48e4-8103-4b093cc59269"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Training:   2%|‚ñè         | 13/591 [00:15<09:26,  1.02it/s]/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch 1 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 591/591 [10:58<00:00,  1.11s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [1/5] Train Loss: 0.8430 | Train Acc: 72.21% | Valid Loss: 0.5593 | Valid Acc: 81.93%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 591/591 [10:44<00:00,  1.09s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [2/5] Train Loss: 0.5221 | Train Acc: 83.06% | Valid Loss: 0.5366 | Valid Acc: 83.16%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 591/591 [10:42<00:00,  1.09s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [3/5] Train Loss: 0.4147 | Train Acc: 86.40% | Valid Loss: 0.4386 | Valid Acc: 85.87%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4 - Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 591/591 [10:41<00:00,  1.09s/it]\n"
          ]
        }
      ]
    }
  ]
}